{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fbd18a-4296-49f7-b0fb-274672de288d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb092649-2740-408e-93ed-49c93f954660",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924298fd-41c5-4409-b7ff-23bda467d686",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06824235-00ce-42ae-ac96-924a3c964a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8b576d6-c65a-4f1c-94fd-9ec68932d324",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e6ba8bb-3160-40f3-92d2-ddc351fdaa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from moviepy.editor import VideoFileClip, concatenate_videoclips\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "643b398b-06cf-4ae7-8675-b07c4c5af884",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import librosa\n",
    "# from moviepy.editor import *\n",
    "from moviepy import VideoFileClip, AudioFileClip, concatenate_videoclips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746d6bd7-04bf-482d-8a05-20e4a084adda",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install wxPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28e3e1a7-3cce-4041-b5b3-d87306c42a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: regex in ./.venv310/lib/python3.10/site-packages (2025.9.18)\n"
     ]
    }
   ],
   "source": [
    "!pip install regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c7336bf-9d03-4e4b-aff6-ca092fb16fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyo\n",
    "from pyo import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64f502a8-3d58-4bf3-9bc1-9232948e6558",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re, unicodedata, math\n",
    "import numpy as np\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e06c83a1-84c1-4299-96a4-7e8e093abe27",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Download Unicode Scripts.txt (nned to run only once; you can also cache this locally)\n",
    "SCRIPTS_URL = \"https://www.unicode.org/Public/UCD/latest/ucd/Scripts.txt\"\n",
    "\n",
    "\n",
    "# ALL SCRIPTS 'UNDER THE SUN' [IN UNICODE, THAT IS]\n",
    "\n",
    "import regex\n",
    "import urllib.request\n",
    "\n",
    "\n",
    "def get_all_scripts() -> set[str]:\n",
    "    \"\"\"\n",
    "    Fetch the official Unicode script names from Scripts.txt.\n",
    "    \"\"\"\n",
    "    with urllib.request.urlopen(SCRIPTS_URL) as f:\n",
    "        lines = f.read().decode(\"utf-8\").splitlines()\n",
    "\n",
    "    scripts = set()\n",
    "    for line in lines:\n",
    "        if line.strip() and not line.startswith(\"#\"):\n",
    "            # Example line: \"0041..005A; Latin # L&  [26] LATIN CAPITAL LETTER A..Z\"\n",
    "            parts = line.split(\";\")\n",
    "            if len(parts) >= 2:\n",
    "                script = parts[1].strip().split()[0]\n",
    "                scripts.add(script)\n",
    "    return scripts\n",
    "\n",
    "UNICODE_SCRIPTS = sorted(get_all_scripts())\n",
    "\n",
    "def char_script(ch):\n",
    "    import regex\n",
    "    \n",
    "    if not ch or len(ch) != 1:\n",
    "        return \"INVALID\"\n",
    "\n",
    "    for script in UNICODE_SCRIPTS:\n",
    "        try:\n",
    "            # Use the script name exactly as Unicode defines it\n",
    "            if regex.match(rf\"\\p{{Script={script}}}\", ch):\n",
    "                return script  # return it as-is\n",
    "        except regex.error:\n",
    "            continue  # skip invalid/unrecognized scripts\n",
    "\n",
    "    return \"UNKNOWN\"\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def word_script(word: str) -> str:\n",
    "    \"\"\"\n",
    "    Return the dominant script of a word (based on majority of alphabetic chars).\n",
    "    \"\"\"\n",
    "    scripts = Counter(char_script(ch) for ch in word if ch.isalpha())\n",
    "    return scripts.most_common(1)[0][0] if scripts else \"OTHER\"\n",
    "\n",
    "\n",
    "def get_unicode_name(ch):\n",
    "    try:\n",
    "        return unicodedata.name(ch)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "\n",
    "import unicodedata\n",
    "\n",
    "# Latin/Cyrillic/Greek/Devanagari vowels (extendable)\n",
    "_vowel_re_latin = re.compile(r\"[aeiouy\\u00E0-\\u00FF]+\", re.IGNORECASE)\n",
    "_vowel_re_cyrillic = re.compile(r\"[аеёиоуыэюя]+\", re.IGNORECASE)  # basic Russian vowels\n",
    "_vowel_re_greek = re.compile(r\"[αεηιουωάέήίόύώ]\", re.IGNORECASE)   # modern Greek vowels\n",
    "_vowel_re_devanagari = re.compile(r\"[अआइईउऊएऐओऔऋॠॡॢॣ]\", re.IGNORECASE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dd27c2-9691-4b17-b33b-f05c32d2456d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75209634-44a8-4de0-a0c8-06bc3a2cd274",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /Users/raluca/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/raluca/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw to /Users/raluca/nltk_data...\n",
      "[nltk_data]   Package omw is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/raluca/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def approx_syllables_word(word: str) -> int:\n",
    "    if not word:\n",
    "        return 0\n",
    "    w = unicodedata.normalize(\"NFC\", word)\n",
    "    script = word_script(w)\n",
    "\n",
    "    if script == \"LATIN\":\n",
    "        groups = _vowel_re_latin.findall(w)\n",
    "        count = len(groups)\n",
    "        if w.lower().endswith(\"e\") and count > 1:  # silent 'e'\n",
    "            count -= 1\n",
    "        return max(1, count)\n",
    "\n",
    "    if script == \"CYRILLIC\":\n",
    "        groups = _vowel_re_cyrillic.findall(w)\n",
    "        return max(1, len(groups))\n",
    "\n",
    "    if script == \"GREEK\":\n",
    "        groups = _vowel_re_greek.findall(w)\n",
    "        return max(1, len(groups))\n",
    "\n",
    "    if script == \"DEVANAGARI\":\n",
    "        groups = _vowel_re_devanagari.findall(w)\n",
    "        return max(1, len(groups))\n",
    "\n",
    "    if script in (\"HIRAGANA\", \"KATAKANA\"):\n",
    "        kana_chars = [ch for ch in w if '\\u3040' <= ch <= '\\u30FF']\n",
    "        return max(1, len(kana_chars))\n",
    "\n",
    "    if script == \"HANGUL\":\n",
    "        return len([ch for ch in w if '\\uAC00' <= ch <= '\\uD7A3'])\n",
    "\n",
    "    if script == \"CJK\":\n",
    "        chars = [ch for ch in w if '\\u4E00' <= ch <= '\\u9FFF']\n",
    "        return max(1, len(chars))\n",
    "\n",
    "    if script == \"THAI\":\n",
    "        return max(1, len([ch for ch in w if ch.strip()]))\n",
    "\n",
    "    # Fallback\n",
    "    groups = _vowel_re_latin.findall(w)\n",
    "    return max(1, len(groups) if groups else len(w))\n",
    "\n",
    "\n",
    "def extract_phonological_clusters(word: str):\n",
    "    clusters = set()\n",
    "    w = unicodedata.normalize(\"NFC\", word.lower())\n",
    "    script = word_script(w)\n",
    "\n",
    "    if script in (\"LATIN\", \"GREEK\", \"CYRILLIC\"):\n",
    "        consonant_matches = re.findall(r'[^aeiouy]+', w)\n",
    "        for c in consonant_matches:\n",
    "            for i in range(len(c)):\n",
    "                for j in range(i+1, len(c)+1):\n",
    "                    clusters.add(c[i:j])\n",
    "        vowel_matches = re.findall(r'[aeiouy]+', w)\n",
    "        for v in vowel_matches:\n",
    "            for i in range(len(v)):\n",
    "                for j in range(i+1, len(v)+1):\n",
    "                    clusters.add(v[i:j])\n",
    "        for k in range(2, 5):\n",
    "            if len(w) >= k:\n",
    "                clusters.add(w[-k:])\n",
    "\n",
    "    elif script in (\"ARABIC\", \"HEBREW\"):\n",
    "        consonant_runs = re.findall(r'[^aeiou]+', w)\n",
    "        for c in consonant_runs:\n",
    "            for i in range(len(c)):\n",
    "                for j in range(i+1, len(c)+1):\n",
    "                    clusters.add(c[i:j])\n",
    "        for k in range(2, 5):\n",
    "            if len(w) >= k:\n",
    "                clusters.add(w[-k:])\n",
    "\n",
    "    elif script == \"DEVANAGARI\":\n",
    "        groups = _vowel_re_devanagari.findall(w)\n",
    "        for g in groups:\n",
    "            clusters.add(g)\n",
    "        for k in range(2, 5):\n",
    "            if len(w) >= k:\n",
    "                clusters.add(w[-k:])\n",
    "\n",
    "    elif script in (\"HIRAGANA\", \"KATAKANA\", \"HANGUL\", \"CJK\"):\n",
    "        chars = list(w)\n",
    "        clusters.update(chars)\n",
    "        for i in range(len(chars)-1):\n",
    "            clusters.add(chars[i] + chars[i+1])\n",
    "\n",
    "    else:\n",
    "        for i in range(len(w)):\n",
    "            for j in range(i+1, min(i+4, len(w))+1):\n",
    "                clusters.add(w[i:j])\n",
    "\n",
    "    return clusters\n",
    "\n",
    "\n",
    "_word_re = re.compile(r\"\\w+\", re.UNICODE)\n",
    "\n",
    "def tokenize_text(text):\n",
    "    tokens = []\n",
    "    for m in _word_re.finditer(text):\n",
    "        tok = m.group(0)\n",
    "        tokens.append(tok)\n",
    "    return tokens\n",
    "\n",
    "_fricatives = set(list(\"fvsz\") + [\"sh\",\"zh\",\"th\"])\n",
    "_plosives = set(list(\"pbtdkg\"))\n",
    "\n",
    "def phonetic_density(tokens):\n",
    "    latin_tokens = [t for t in tokens if char_script(t[0]) == \"LATIN\"]\n",
    "    joined = \" \".join(latin_tokens).lower()\n",
    "    letters = re.sub(r'[^a-z]', '', joined)\n",
    "    if not letters:\n",
    "        return 0.0, 0.0, 0.0\n",
    "    fric_count = sum(joined.count(f) for f in [\"f\",\"v\",\"s\",\"z\",\"sh\",\"zh\",\"th\"])\n",
    "    plos_count = sum(joined.count(p) for p in [\"p\",\"b\",\"t\",\"d\",\"k\",\"g\"])\n",
    "    vowel_count = sum(1 for c in letters if c in \"aeiouy\")\n",
    "    total = len(letters)\n",
    "    return fric_count/total, plos_count/total, vowel_count/(total+1e-9)\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import words, stopwords, wordnet as wn\n",
    "from nltk.corpus.reader import WordListCorpusReader\n",
    "import numpy as np\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('words')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('omw')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# Load English words and stopwords\n",
    "english_words = set(words.words())\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Define common prefixes and suffixes\n",
    "PL_PREFIXES = {\"re\", \"un\", \"in\", \"dis\", \"pre\", \"sub\"}\n",
    "PL_SUFFIXES = {\"ing\", \"ed\", \"er\", \"ly\", \"es\", \"ful\"}\n",
    "\n",
    "def is_plausible_fragment(fragment):\n",
    "    \"\"\"Check if fragment is a plausible English word, prefix/suffix, or foreign fragment.\"\"\"\n",
    "    fragment = fragment.lower()\n",
    "    if not fragment:\n",
    "        return False\n",
    "    if fragment in english_words:\n",
    "        return True\n",
    "    if fragment in PL_PREFIXES or fragment in PL_SUFFIXES:\n",
    "        return True\n",
    "    # Check if fragment exists in WordNet for any language\n",
    "    for lang in wn.langs():\n",
    "        if wn.synsets(fragment, lang=lang):\n",
    "            return True\n",
    "    # Fallback: accept fragments that are at least 2 characters long\n",
    "    if len(fragment) > 1:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def extract_audio_features_from_stanza(stanza, expected_feet_per_line=(5,6), foot_syllables=(2,3)):\n",
    "    lines = [ln.strip() for ln in stanza.strip().split(\"\\n\") if ln.strip()]\n",
    "    n_lines = max(1, len(lines))\n",
    "    tokens = tokenize_text(stanza)\n",
    "    syll_counts_tokens = [approx_syllables_word(t) for t in tokens]\n",
    "    total_syllables = sum(syll_counts_tokens)\n",
    "    n_words = len(tokens) if tokens else 1\n",
    "    syllable_density = total_syllables / n_words if n_words else 0.0\n",
    "    target_feet = np.mean(expected_feet_per_line)\n",
    "    avg_syll_per_line = total_syllables / max(1, len(lines))\n",
    "    avg_foot_syll = np.mean(foot_syllables)\n",
    "    tempo = avg_syll_per_line / avg_foot_syll\n",
    "    sylls_per_line = [sum(approx_syllables_word(t) for t in tokenize_text(ln)) for ln in lines]\n",
    "    pacing_variance = float(np.var(sylls_per_line)) if sylls_per_line else 0.0\n",
    "    fric_density, plos_density, vowel_ratio = phonetic_density(tokens)\n",
    "    vocal_smoothness = float(vowel_ratio)\n",
    "\n",
    "    # --- [word-splitting] enjambment detection (needed in this specific case; if you need to process enjambments in general see https://github.com/Margento/Computationally_Assembled_Belgian_Poetry_Anthology ---\n",
    "    enjambments = 0\n",
    "    enjambed_positions = set()\n",
    "\n",
    "    for ln_idx, ln in enumerate(lines):\n",
    "        # 1. End-of-line split (including ellipses)\n",
    "        end_match = re.search(r'(\\w+(?:\\.\\.\\.)?)-/?(\\w*)$', ln)\n",
    "        if end_match:\n",
    "            left, right = end_match.groups()\n",
    "            if is_plausible_fragment(left) and (not right or is_plausible_fragment(right)):\n",
    "                enjambments += 1\n",
    "                enjambed_positions.add(end_match.start())\n",
    "\n",
    "        # 2. Start-of-line split\n",
    "        if ln_idx > 0:\n",
    "            start_match = re.match(r'^(\\w*)-/(\\w+)', ln)\n",
    "            if start_match:\n",
    "                left, right = start_match.groups()\n",
    "                if (not left or is_plausible_fragment(left)) and is_plausible_fragment(right):\n",
    "                    enjambments += 1\n",
    "                    enjambed_positions.add(start_match.start())\n",
    "\n",
    "        # 3. Multi-word or foreign-word consideration (fallback)\n",
    "        for match in re.finditer(r'(\\S+)/(\\S+)', ln):\n",
    "            left, right = match.groups()\n",
    "            if is_plausible_fragment(left) and is_plausible_fragment(right):\n",
    "                enjambments += 1\n",
    "                enjambed_positions.add(match.start())\n",
    "\n",
    "    # Count pause marks excluding those part of valid enjambments\n",
    "    pause_marks = 0\n",
    "    for m in re.finditer(r'[,;:\\-\\—\\(\\)]', stanza):\n",
    "        if m.start() not in enjambed_positions:\n",
    "            pause_marks += 1\n",
    "\n",
    "    silence_ratio = pause_marks / (total_syllables + 1e-9)\n",
    "    caesura = sum(1 for ln in lines if \",\" in ln or \";\" in ln or \"—\" in ln)\n",
    "\n",
    "    enjambments_norm = enjambments / n_lines\n",
    "    caesura_norm = caesura / n_lines\n",
    "\n",
    "    audio = {\n",
    "        \"syllable_density\": float(syllable_density),\n",
    "        \"tempo\": float(tempo),\n",
    "        \"pacing_variance\": float(pacing_variance),\n",
    "        \"fricative_density\": float(fric_density),\n",
    "        \"plosive_density\": float(plos_density),\n",
    "        \"vocal_smoothness\": float(vocal_smoothness),\n",
    "        \"silence_ratio\": float(silence_ratio),\n",
    "        \"total_syllables\": int(total_syllables),\n",
    "        \"sylls_per_line\": sylls_per_line,\n",
    "        \"enjambments\": float(enjambments_norm),\n",
    "        \"caesura\": float(caesura_norm),\n",
    "        \"n_words\": n_words\n",
    "    }\n",
    "    return audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37821939-9aaa-416b-a8b6-48a151659faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91b98489-446f-473f-b6fa-0235f0f1e400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Using Apple Silicon GPU via MPS\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# IN CASE YOU ARE ON MPS\n",
    "\n",
    "import torch\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"✅ Using Apple Silicon GPU via MPS\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"⚠️ MPS not available, falling back to CPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb23b66-a64a-4afc-91cd-349f77fbb9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f051b63b-a25e-4e0c-b25a-c7d70271e4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade protobuf sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "697039f6-0faf-440c-84c1-0ff864661586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a9391c-55ba-4ef1-960c-b775c8f63bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65194f27-fa19-40b6-8a23-91fdbf52725e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import XLMRobertaTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "# import torch\n",
    "\n",
    "# Model + tokenizer\n",
    "model_name = \"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
    "tokenizer = XLMRobertaTokenizer.from_pretrained(model_name)  # force slow tokenizer\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Pipeline\n",
    "sentiment_pipeline = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device=device\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4d41ab78-b039-4347-a4a2-c1c678c08025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'positive', 'score': 0.7629498839378357}]\n",
      "[{'label': 'positive', 'score': 0.944301426410675}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# TESTING THE AFFECT PIPELINE\n",
    "print(sentiment_pipeline(\"This is working now! 🚀\"))\n",
    "print(sentiment_pipeline(\"I am loving this! ❤️\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3554e86e-8b53-4398-a431-3f9cc6b8e934",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# AFFECT/SENTIMENT ANALYSIS\n",
    "\n",
    "import math\n",
    "\n",
    "def stanza_affect_vector(stanza):\n",
    "    \"\"\"\n",
    "    Extract affective features (valence, arousal, energy) from a stanza of text,\n",
    "    combining multilingual sentiment analysis with audio-like features.\n",
    "    \"\"\"\n",
    "\n",
    "    # --- 1. Multilingual Sentiment Analysis (Hugging Face) ---\n",
    "    try:\n",
    "        sentiment_result = sentiment_pipeline(stanza[:512])[0]  # truncate to model limit\n",
    "        label = sentiment_result[\"label\"].lower()\n",
    "        score = sentiment_result[\"score\"]\n",
    "\n",
    "        # Map labels to a polarity value in [-1, 1]\n",
    "        if \"negative\" in label:\n",
    "            polarity = -score\n",
    "        elif \"positive\" in label:\n",
    "            polarity = score\n",
    "        else:  # neutral\n",
    "            polarity = 0.0\n",
    "    except Exception as e:\n",
    "        print(f\"Sentiment analysis failed: {e}\")\n",
    "        polarity = 0.0\n",
    "\n",
    "    # Calculate valence from polarity\n",
    "    valence = float(math.tanh(polarity * 5.0))\n",
    "\n",
    "    # --- 2. Extract \"audio\" features ---\n",
    "    audio_feats = extract_audio_features_from_stanza(stanza)\n",
    "\n",
    "    # --- 3. Calculate arousal & energy ---\n",
    "    arousal = (audio_feats[\"pacing_variance\"] ** 0.5\n",
    "               + audio_feats[\"fricative_density\"] * 0.5\n",
    "               + min(1.0, audio_feats[\"silence_ratio\"] * 2.0))\n",
    "    arousal = float(math.tanh(arousal))\n",
    "\n",
    "    energy = float(math.tanh(\n",
    "        (audio_feats[\"tempo\"] * 0.6) +\n",
    "        (audio_feats[\"syllable_density\"] * 0.2)\n",
    "    ))\n",
    "\n",
    "    return {\n",
    "        \"valence\": valence,\n",
    "        \"arousal\": arousal,\n",
    "        \"energy\": energy,\n",
    "        # \"audio_feats\": audio_feats\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bc9b62a4-dd3a-43f2-ae04-a0469ff952c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TEMPORAL FEATURES\n",
    "def stanza_temporal_structures(stanza):\n",
    "    lines = [ln.strip() for ln in stanza.strip().split(\"\\n\") if ln.strip()]\n",
    "    n_segments = len(lines)\n",
    "    segment_annotations = []\n",
    "    motifs_counter = Counter()\n",
    "    \n",
    "    # process clusters instead of whole words\n",
    "    for i, ln in enumerate(lines):\n",
    "        words = tokenize_text(ln)\n",
    "        segment_annotations.append(\n",
    "            f\"line_{i+1}: {len(words)} words, {sum(approx_syllables_word(w) for w in words)} sylls\"\n",
    "        )\n",
    "        for w in words:\n",
    "            clusters = extract_phonological_clusters(w)\n",
    "            for c in clusters:\n",
    "                motifs_counter[c] += 1\n",
    "    \n",
    "    motifs = [cl for cl,cnt in motifs_counter.items() if cnt > 1]\n",
    "    n_motifs = len(motifs)\n",
    "    n_uniques = len(motifs_counter)\n",
    "    \n",
    "    sylls_per_line = [\n",
    "        sum(approx_syllables_word(w) for w in tokenize_text(ln)) for ln in lines\n",
    "    ] if lines else []\n",
    "    \n",
    "    ruptures = []\n",
    "    if sylls_per_line:\n",
    "        mean = np.mean(sylls_per_line); sd = np.std(sylls_per_line)\n",
    "        for i, s in enumerate(sylls_per_line):\n",
    "            if sd > 0 and abs(s-mean) > 1.5*sd:\n",
    "                ruptures.append({\n",
    "                    \"line\": i+1, \n",
    "                    \"syllables\": int(s), \n",
    "                    \"deviation\": float((s-mean)/sd)\n",
    "                })\n",
    "    \n",
    "    score_linear = 0.0\n",
    "    if len(sylls_per_line) > 1:\n",
    "        x = np.arange(len(sylls_per_line))\n",
    "        y = np.array(sylls_per_line)\n",
    "        cov = np.cov(x, y)[0,1]\n",
    "        if np.std(x) > 0 and np.std(y) > 0:\n",
    "            score_linear = float(cov / (np.std(x) * np.std(y)))\n",
    "    \n",
    "    score_cyclical = 0.0\n",
    "    if len(sylls_per_line) > 2:\n",
    "        y = np.array(sylls_per_line) - np.mean(sylls_per_line)\n",
    "        score_cyclical = float(np.correlate(y, np.roll(y,1))[0] / (np.sum(y*y)+1e-9))\n",
    "    \n",
    "    ngrams = Counter()\n",
    "    for ln in lines:\n",
    "        toks = [t.lower() for t in tokenize_text(ln)]\n",
    "        for i in range(len(toks)-1):\n",
    "            ngrams[\" \".join(toks[i:i+2])] += 1\n",
    "    repeated_ngrams = sum(1 for c in ngrams.values() if c>1)\n",
    "    score_recursive = float(repeated_ngrams / (len(ngrams)+1e-9))\n",
    "    score_hybrid = float((abs(score_linear) + abs(score_cyclical) + score_recursive)/3.0)\n",
    "    \n",
    "    recursive_events = motifs[:5]\n",
    "    \n",
    "    return {\n",
    "        \"segments\": n_segments,\n",
    "        \"segment_annotations\": segment_annotations,\n",
    "        \"number_of_motifs\": n_motifs,\n",
    "        \"motifs\": motifs,\n",
    "        \"uniques\": n_uniques,\n",
    "        \"ruptures\": ruptures,\n",
    "        \"score_linear\": round(score_linear, 3),\n",
    "        \"score_cyclical\": round(score_cyclical, 3),\n",
    "        \"score_recursive\": round(score_recursive, 3),\n",
    "        \"score_hybrid\": round(score_hybrid, 3),\n",
    "        \"recursive_events\": recursive_events\n",
    "    }\n",
    "\n",
    "def extract_full_stanza_representation(stanza):\n",
    "    audio_feats =  extract_audio_features_from_stanza(stanza)\n",
    "    affect = stanza_affect_vector(stanza)\n",
    "    temporal = stanza_temporal_structures(stanza)\n",
    "\n",
    "    return {\n",
    "        \"audio_features\": audio_feats,\n",
    "        \"affect_vector\": affect,\n",
    "        \"temporal_features\": temporal,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e97aeda-3093-4b9d-b3c4-06e5b0f9dffa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d26dcef3-3052-462e-899f-6702f80b434e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TEXT OF \"World Poem I. Foundational Quantum Mechanics, AHiRA, & CMoLA\" by MARGENTO\n",
    "# REPLACE WITH YOUR OWN STANZAS\n",
    "\n",
    "stanza_0 = \"\"\"\n",
    "         W   que\t\t\t   S  outh\n",
    "   in\t\t  quirir\t         to\t      \t            chase\n",
    "       con\t\tquirimos\tthe\t      \tchases\n",
    "\t      ad\t\t\t             per\n",
    "\"\"\"\n",
    "\n",
    "stanza_1 = \"\"\"\n",
    "uje adujo adujiste adari adz adâncu dus d(vr)ut\n",
    "\t   duce ado thaws injudicious, odd airy $nazzy Duke’s di(¢)tion (Φ)root \n",
    "\n",
    "   \tOcaso que no hemos todavía podido averisnar quién es el auto\n",
    "   \t   acasă un sun$eth to dive in, airpods on, getting aut(h)o® ads\n",
    "\n",
    "\tLa obra musical, como el animal, transmite la vida que ha recibido\n",
    "\t   for being musical is being animal, trans smithing avidly the recipe tome\n",
    "\"\"\"\n",
    "\n",
    "stanza_2 = \"\"\"\n",
    "No \t\n",
    "        pue\t \tson\n",
    "           den \t\t         \n",
    "     ser \t                  sí\n",
    "      \t\t   hijos       \n",
    "        del             legítimos \n",
    "              \t Arti\t\t Arte\n",
    "        \t\tfici\n",
    "o\n",
    "\t\t\t\n",
    "\t\t\tf\n",
    "\t\t\tΦi\t $(i)on\n",
    "\t\t\t¢€\t   ¢$ \n",
    "\t\t      re\n",
    "\t\t           ®\n",
    "\t           Aut(E)o\n",
    "\t                     outer\n",
    "                                 oughta\n",
    "                            ghτer  \n",
    "the           Δau\n",
    "\"\"\"\n",
    "\n",
    "stanza_3 = \"\"\"\n",
    "         Y el afán de identificarse con tualidad; porque en $uma, \n",
    "being a fan for trendy farces by con dads, tu-i porcu’i muma\n",
    "\n",
    "         ¿qué son los poetas más – ella no lleva a la muerte, \n",
    "de sonorous poetic mess—mass, Ella & Billie style assertive\n",
    "\n",
    "         sino a una vida – que los poseedores del maravilloso\n",
    "sinning ’n g’ luna void key low, posey odors, a deli marries via Zoso …\n",
    "\n",
    "         poder expreso – más plena y más completa… \n",
    "power ’v eXpress oh--my ass, plain, I must complain …\n",
    "\"\"\"\n",
    "\n",
    "stanza_4 = \"\"\"\n",
    "soñ\tEN señ          son\t        E$ sign\n",
    "  que           ab[β]a \t    ic\t       lava\n",
    "\t\tni\t\t               t @t €\n",
    "       ro\t           un\t     gr\t         ion\n",
    "\t    lib\t\t\t  εr®\n",
    "\"\"\"\n",
    "\n",
    "stanza_5 = \"\"\"\n",
    "                                                      en secreto\n",
    "El hombre que conSt mi sueño, los ojos, el fardo, nos dicen – amor, su alfabeto –\n",
    "                                    minä’ tejin’ käminä’\t\t        ὕ   \n",
    "   all amber, Zoque it, mine me sayin’, insecure sod — a morsel, all, the fabri¢ back-to\n",
    "\n",
    "                                \t\t\t\t\t\t    posesión de\n",
    "profundizar ES materias, nuidad de la existencia, entra o toma un organismo físico,\n",
    "         τ ℕ\t         $\t\t\t\t\t                 Poseidon’s twin\n",
    "   professionals ’n’ materials, nudity delete extinction, enter ol’ Thomas and comes mystically\n",
    "\n",
    "cn que se trata\t   en la mente d\n",
    "en nOS tribunales, penetrar    el médium y darle expresión % escritura automática\n",
    "   as the letter c                 a lamented d\t\t\t        Zong!\t     ray  awe\t\t  τ\n",
    "   in matriarchal menace, prota amari,       e-al£ made in his im®age, ex carbON ton(€)omous Arcti¢a\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "stanza_6 = \"\"\"\n",
    "           es una\n",
    "   e££a \t\t  his\n",
    "  nov\t\t   tor\t\t             que\n",
    "             \t              i\t\t\t  Φ is i   x\n",
    "        anu se     a\t\t           \t                $\n",
    "\t\t    ®t\t\t               no\n",
    "\t\t\ti  \tΦ ic i  al  $α\n",
    "da\t\tdă\t\t    wa   a do\n",
    "  vi\tvi\n",
    "\t\t     £\n",
    "pAso\ta PaSo\t\n",
    "\t\t$tep\tby    s(To)p   litter\n",
    "\t\t\t    be\t   AM\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d989521a-7be2-4895-b194-4dcb0fc53e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features_0 = extract_full_stanza_representation(stanza_0)\n",
    "features_1 = extract_full_stanza_representation(stanza_1)\n",
    "features_2 = extract_full_stanza_representation(stanza_2)\n",
    "features_3 = extract_full_stanza_representation(stanza_3)\n",
    "features_4 = extract_full_stanza_representation(stanza_4)\n",
    "features_5 = extract_full_stanza_representation(stanza_5)\n",
    "features_6 = extract_full_stanza_representation(stanza_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d7c78f0-ea50-459d-92c4-77931be8df42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#stanzas = []\n",
    "stanzas = [features_0, features_1, features_2, features_3, features_4, features_5, features_6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573f3de1-4a90-473d-b392-09b2732d6021",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install pydub ffmpeg-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3dcc69-e538-4c86-9d74-2f4b67ac5b42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b747fc-ad94-4800-a901-f8e1d1280d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# AUDIO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54920e43-d964-46d8-9b45-8a20a7179acc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b9c6b4cd-7f75-45bc-8ef2-54e673caf258",
   "metadata": {},
   "outputs": [],
   "source": [
    "stanza_lengths = [15, 25, 25, 35, 20, 75, 25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "942004e5-a603-4127-9a11-994454ad77af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pyo warning: Portmidi warning: no midi device found!\n",
      "Portmidi closed.\n",
      "🎧 Stanza recordings will be saved to: world_poem_1_stanza_wavs_2025-10-08/\n",
      "▶ Stanza 1 freq≈55.0Hz amp≈0.53\n",
      "▶ Stanza 2 freq≈93.9Hz amp≈0.60\n",
      "▶ Stanza 3 freq≈55.0Hz amp≈0.37\n",
      "▶ Stanza 4 freq≈75.3Hz amp≈0.60\n",
      "▶ Stanza 5 freq≈55.0Hz amp≈0.53\n",
      "▶ Stanza 6 freq≈102.4Hz amp≈0.60\n",
      "▶ Stanza 7 freq≈55.0Hz amp≈0.48\n",
      "✅ Recording finished for all stanzas\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "Sonification engine (pyo)\n",
    "Adds optional layers:\n",
    " - self-referential recursion feedback (Option 3)\n",
    " - lexical uniqueness shimmer\n",
    " - recursive-motif pings\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "use_recursion_feedback = True      # stanza-level self-reference\n",
    "use_uniques_layer      = True      # lexical diversity shimmer\n",
    "use_recursive_pings    = True      # motif memory pings\n",
    "\n",
    "fade_time = 2.0\n",
    "# stanza_lengths = [15, 25, 25, 35, 20, 75, 25] # REPLACE WITH DURATIONS OF YOUR OWN STANZAS\n",
    "\n",
    "# ---------------- MAPPINGS ----------------\n",
    "def tempo_to_freq(tempo, base_freq=110.0, scale=2.0, tempo_ref=10.0,\n",
    "                  min_freq=55.0, max_freq=1760.0):\n",
    "    tempo = max(0.0001, float(tempo))\n",
    "    freq = base_freq * (scale ** (math.log(tempo / tempo_ref, 2)))\n",
    "    return max(min_freq, min(max_freq, freq))\n",
    "\n",
    "def energy_to_amp(e): return max(0.01, min(1.2, float(e))) * 0.6\n",
    "def arousal_to_bright(a): return max(0.0, min(1.0, float(a)))\n",
    "def fric_to_noise(f): return max(0.0, min(1.0, float(f)))\n",
    "def plosive_to_click_strength(p): return max(0.0, min(1.5, float(p)))\n",
    "def vocal_smooth_to_cutoff(vs): return 500.0 + float(vs) * 5500.0\n",
    "\n",
    "# ---------------- SERVER ----------------\n",
    "s = Server(duplex=0).boot()\n",
    "s.start()\n",
    "# master_mix = Sig(0)\n",
    "# rec_master = Record(master_mix, filename=\"world_poem_1_sonification_master.wav\",\n",
    "                    # fileformat=0, sampletype=1)\n",
    "\n",
    "# rec_master = Record(s.amp, filename=\"world_poem_1_sonification_master.wav\",\n",
    "                    # fileformat=0, sampletype=1)\n",
    "\n",
    "# rec_master.start()\n",
    "\n",
    "# ---------------- HELPERS ----------------\n",
    "def make_rupture_schedule(stanza_idx, stanza, start, dur):\n",
    "    out, tf = [], stanza.get(\"temporal_features\", {})\n",
    "    segs = tf.get(\"segments\", 0)\n",
    "    for r in tf.get(\"ruptures\", []):\n",
    "        frac = float(r.get(\"line\", 1)-1) / max(1, segs)\n",
    "        strength = min(1.6, abs(r.get(\"deviation\", 0)))\n",
    "        out.append((start + frac*dur, strength))\n",
    "    return out\n",
    "\n",
    "def trigger_rupture_burst(strength, panpos):\n",
    "    n = Noise()\n",
    "    hf = Sine(freq=1000+2000*strength)\n",
    "    env = Adsr(0.002, 0.08*strength, 0, 0.02, dur=0.15).play()\n",
    "    nenv = Adsr(0.001, 0.05*strength, 0, 0.01, dur=0.12).play()\n",
    "    Pan(hf*0.6*strength*env + n*0.3*strength*nenv, pan=panpos).out()\n",
    "\n",
    "# ---------------- MAIN ----------------\n",
    "\n",
    "import os, datetime\n",
    "\n",
    "folder_name = f\"world_poem_1_stanza_wavs_{datetime.date.today().isoformat()}\"\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "print(f\"🎧 Stanza recordings will be saved to: {folder_name}/\")\n",
    "\n",
    "\n",
    "global_time = 0.0\n",
    "for i, stanza in enumerate(stanzas):\n",
    "    dur = stanza_lengths[i]\n",
    "    af, av, tf = stanza[\"audio_features\"], stanza[\"affect_vector\"], stanza[\"temporal_features\"]\n",
    "\n",
    "    base_freq = tempo_to_freq(af.get(\"tempo\", 4.0))\n",
    "    base_amp  = energy_to_amp(av.get(\"energy\", 0.8))\n",
    "    bright    = arousal_to_bright(av.get(\"arousal\", 0.5))\n",
    "    noise_lvl = fric_to_noise(af.get(\"fricative_density\", 0.0))\n",
    "    plosive_strength = plosive_to_click_strength(af.get(\"plosive_density\", 0.0))\n",
    "    cutoff    = vocal_smooth_to_cutoff(af.get(\"vocal_smoothness\", 0.3))\n",
    "    score_lin = tf.get(\"score_linear\", 0.0)\n",
    "    score_cyc = tf.get(\"score_cyclical\", 0.0)\n",
    "    score_rec = tf.get(\"score_recursive\", 0.0)\n",
    "\n",
    "    print(f\"▶ Stanza {i+1} freq≈{base_freq:.1f}Hz amp≈{base_amp:.2f}\")\n",
    "\n",
    "    amp_ctrl = SigTo(value=0.0, time=fade_time, init=0.0)\n",
    "\n",
    "    # pacing variance “breathing”\n",
    "    pv = float(af.get(\"pacing_variance\", 1.0))\n",
    "    lfo_rate  = 0.05 + min(0.8, pv / 25.0)\n",
    "    lfo_depth = 2.0 + min(20.0, pv * 0.6)\n",
    "    pacing_lfo = Sine(freq=lfo_rate, mul=lfo_depth)\n",
    "\n",
    "    # wander\n",
    "    wander = SigTo(base_freq, time=5.0)\n",
    "    def new_wander(): wander.value = base_freq * (1.0 + random.uniform(-0.02,0.02))\n",
    "    Pattern(new_wander, time=max(2.0, dur/6.0)).play()\n",
    "\n",
    "    # optional recursion feedback (metamorphic)\n",
    "    fb = Sig(0)\n",
    "    if use_recursion_feedback:\n",
    "        rec_gain = min(0.25, score_rec * 0.5)\n",
    "        fb_lfo = Sine(freq=0.1 + score_rec * 0.3, mul=base_freq * rec_gain)\n",
    "        modulated_freq = base_freq + pacing_lfo + wander + fb_lfo + fb\n",
    "    else:\n",
    "        modulated_freq = base_freq + pacing_lfo + wander\n",
    "\n",
    "    vib_lfo = Sine(freq=0.15, mul=3.0)\n",
    "    carrier = Sine(freq=modulated_freq + vib_lfo, mul=0.0)\n",
    "    if use_recursion_feedback: fb.value = carrier * rec_gain\n",
    "\n",
    "    carrier_amp = carrier * amp_ctrl\n",
    "    overtone = Sine(freq=modulated_freq*1.98, mul=bright*0.2)\n",
    "    noise    = Noise(mul=noise_lvl*0.3)\n",
    "    tonal    = ButLP(carrier_amp + overtone + noise, freq=cutoff)\n",
    "\n",
    "    # stereo motion\n",
    "    pan_lfo  = Sine(freq=0.02 + abs(score_cyc)*0.02, mul=0.25, add=0.5)\n",
    "    lin_drift = SigTo(float(score_lin)*0.2, time=dur)\n",
    "    pan_sig  = Clip(pan_lfo + lin_drift, 0.0, 1.0)\n",
    "    stereo   = Pan(tonal, pan=pan_sig).out()\n",
    "\n",
    "    amp_ctrl.value = base_amp\n",
    "    # rec_stanza = Record(stereo, filename=f\"stanza_{i+1}.wav\",\n",
    "                        # fileformat=0, sampletype=1)\n",
    "    rec_stanza = Record(\n",
    "    stereo,\n",
    "    filename=os.path.join(folder_name, f\"stanza_{i+1}.wav\"),\n",
    "    fileformat=0,\n",
    "    sampletype=1\n",
    ")\n",
    "    # rec_stanza.start()\n",
    "\n",
    "    # ruptures\n",
    "    for rt, strength in make_rupture_schedule(i, stanza, global_time, dur):\n",
    "        CallAfter(lambda s=strength: trigger_rupture_burst(s, random.uniform(0.3,0.7)),\n",
    "                  rt - global_time)\n",
    "\n",
    "    # plosive clicks\n",
    "    if plosive_strength > 0.05:\n",
    "        m = Metro(time=1.0/max(0.2, plosive_strength*2.0)).play()\n",
    "        env = TrigEnv(m, table=HannTable(), dur=0.06, mul=plosive_strength*0.08)\n",
    "        Pan(Sine(freq=base_freq*1.5, mul=env), pan=random.uniform(0.3,0.7)).out()\n",
    "\n",
    "    # uniqueness shimmer\n",
    "    if use_uniques_layer:\n",
    "        uniques = tf.get(\"uniques\", 0)\n",
    "        uniq_density = min(0.8, 0.1 + uniques / 750.0)\n",
    "        for _ in range(int(5 + uniq_density*20)):\n",
    "            Sine(freq=random.uniform(1000,6000),\n",
    "                 mul=uniq_density*0.02).out()\n",
    "\n",
    "    # recursive motif pings\n",
    "    if use_recursive_pings:\n",
    "        rec_events = tf.get(\"recursive_events\", [])\n",
    "        ping_rate = max(0.3, 8.0/(len(rec_events)+2))\n",
    "        met = Metro(time=ping_rate).play()\n",
    "        env = TrigEnv(met, HannTable(), dur=0.08, mul=0.04)\n",
    "        Pan(Sine(freq=660+len(rec_events)*3, mul=env),\n",
    "            pan=random.random()).out()\n",
    "\n",
    "    time.sleep(dur)\n",
    "    amp_ctrl.value = 0.0\n",
    "    time.sleep(fade_time)\n",
    "    rec_stanza.stop()\n",
    "    global_time += dur\n",
    "\n",
    "# ---------------- SHUTDOWN ----------------\n",
    "time.sleep(0.5)\n",
    "rec_master.stop()\n",
    "# print(\"✅ Master recording finished: world_poem_1_sonification_master.wav\")\n",
    "print(\"✅ Recording finished for all stanzas\")\n",
    "s.stop(); s.shutdown()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6bb69f-06e4-4b9b-afb2-7a1fa5bc495c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0aa1df4c-4639-4469-adc4-cdffa07e102c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7 stanza files. Concatenating...\n",
      " → Added stanza_1.wav (17.0s)\n",
      " → Added stanza_2.wav (27.0s)\n",
      " → Added stanza_3.wav (27.0s)\n",
      " → Added stanza_4.wav (37.0s)\n",
      " → Added stanza_5.wav (22.0s)\n",
      " → Added stanza_6.wav (77.0s)\n",
      " → Added stanza_7.wav (27.0s)\n",
      "\n",
      "✅ Exported full mix to world_poem_1_full_mix.wav\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pydub import AudioSegment\n",
    "import glob, os\n",
    "\n",
    "# Directory containing stanza WAVs\n",
    "input_dir = \"world_poem_1_stanza_wavs_2025-10-08\"\n",
    "output_wav = \"world_poem_1_full_mix.wav\"\n",
    "\n",
    "# Find all stanza files and sort numerically\n",
    "files = sorted(glob.glob(os.path.join(input_dir, \"stanza_*.wav\")),\n",
    "               key=lambda x: int(\"\".join(filter(str.isdigit, os.path.basename(x))) or 0))\n",
    "\n",
    "if not files:\n",
    "    raise FileNotFoundError(\"No stanza_*.wav files found!\")\n",
    "\n",
    "print(f\"Found {len(files)} stanza files. Concatenating...\")\n",
    "\n",
    "full_mix = AudioSegment.silent(duration=0)\n",
    "\n",
    "for f in files:\n",
    "    seg = AudioSegment.from_wav(f)\n",
    "    full_mix += seg\n",
    "    print(f\" → Added {os.path.basename(f)} ({len(seg)/1000:.1f}s)\")\n",
    "\n",
    "# Export combined WAV\n",
    "full_mix.export(output_wav, format=\"wav\")\n",
    "print(f\"\\n✅ Exported full mix to {output_wav}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad0e140-125b-4154-9d7b-c0f06fe018ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00c132b-dfce-4bb6-b0e5-3acae0aad44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# VIDEO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ac85ce-07a7-40c0-bed7-7c0f07631a14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b8a6d9f7-19f8-4d7e-823e-4a30e7c67cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, math, random\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "#from moviepy.editor import VideoClip, ImageClip, concatenate_videoclips, AudioFileClip\n",
    "from moviepy import VideoClip, AudioFileClip, concatenate_videoclips\n",
    "import librosa\n",
    "from scipy.io import wavfile\n",
    "from scipy.spatial.distance import cosine\n",
    "import difflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69425e24-71e9-4b7e-adf9-5797ba64ac99",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib scipy pillow sentence-transformers pyphonetics jellyfish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553dc3e7-bda1-4b42-8f5c-ba423e2fa951",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# semantic embeddings\n",
    "# if not available, fallback option, difflib\n",
    "try:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    SENT_MODEL = \"paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "    print(\"Loading sentence-transformer\", SENT_MODEL)\n",
    "    s_model = SentenceTransformer(SENT_MODEL)\n",
    "    def semantic_similarity(a,b):\n",
    "        if not a or not b: return 0.0\n",
    "        ea = s_model.encode(a, convert_to_numpy=True)\n",
    "        eb = s_model.encode(b, convert_to_numpy=True)\n",
    "        sim = float(np.dot(ea, eb) / (np.linalg.norm(ea)*np.linalg.norm(eb) + 1e-12))\n",
    "        return max(0.0, min(1.0, (sim+1)/2))\n",
    "except Exception:\n",
    "    s_model = None\n",
    "    import difflib\n",
    "    def semantic_similarity(a,b):\n",
    "        if not a or not b: return 0.0\n",
    "        return difflib.SequenceMatcher(None, a, b).ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f5098971-f507-442b-b41b-7c1249549a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Final integrated version: labels fade-in, pulse couplet flashes, glyph overlays, dynamic plots, recap.\n",
    "\n",
    "\n",
    "# phonetics\n",
    "try:\n",
    "    from pyphonetics import Metaphone\n",
    "    metaphone = Metaphone()\n",
    "    def phonetic_code(s): return metaphone.phonetics(s or \"\")\n",
    "except Exception:\n",
    "    import jellyfish\n",
    "    def phonetic_code(s): return jellyfish.metaphone(s or \"\")\n",
    "\n",
    "\n",
    "JSON_PATH = \"world_poem_1_structure.json\" # REPLACE THIS WITH YOUR OWN POEM (STRUCTURE) JSON\n",
    "AUDIO_MASTER = \"world_poem_1_full_mix.wav\"\n",
    "\n",
    "TMP_DIR = Path(\"tmp_frames_v2\"); TMP_DIR.mkdir(exist_ok=True)\n",
    "W, H = 1280, 720\n",
    "FPS = 24\n",
    "FINAL_LABEL_SECONDS = 3.0\n",
    "ORBIT_LABEL_FADE_STEPS = 10\n",
    "COUPLET_FLASH_SECONDS = 0.8   # each ES or EN flash\n",
    "GLYPH_FLASH_SECONDS = 0.6\n",
    "MIN_COUPLET_SECONDS = 1.0\n",
    "# FONT_PATH = None\n",
    "FONT_PATH = \"Arial_Unicode.ttf\" # If you don't have this (or any other font), comment out and uncomment the line above\n",
    "FONT = None\n",
    "\n",
    "\n",
    "def get_font(sz):\n",
    "    global FONT\n",
    "    if FONT is not None: return FONT\n",
    "    try:\n",
    "        if FONT_PATH:\n",
    "            FONT = ImageFont.truetype(FONT_PATH, sz)\n",
    "        else:\n",
    "            FONT = ImageFont.load_default()\n",
    "    except Exception:\n",
    "        FONT = ImageFont.load_default()\n",
    "    return FONT\n",
    "\n",
    "\n",
    "def load_json(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def save_pil_img(img, p):\n",
    "    p.parent.mkdir(parents=True, exist_ok=True)\n",
    "    img.convert(\"RGB\").save(p)\n",
    "\n",
    "def pil_to_np(img):\n",
    "    return np.array(img.convert(\"RGB\"))\n",
    "\n",
    "def make_blank_frame(color=(6,6,10)):\n",
    "    return Image.new(\"RGB\", (W,H), color)\n",
    "\n",
    "def paste_center(bg, fg, offset=(0,0)):\n",
    "    bx, by = bg.size\n",
    "    fx, fy = fg.size\n",
    "    x = (bx - fx)//2 + offset[0]\n",
    "    y = (by - fy)//2 + offset[1]\n",
    "    b2 = bg.copy()\n",
    "    b2.paste(fg, (x,y), fg if fg.mode==\"RGBA\" else None)\n",
    "    return b2\n",
    "\n",
    "def phonetic_similarity(a,b):\n",
    "    ca = phonetic_code(a or \"\")\n",
    "    cb = phonetic_code(b or \"\")\n",
    "    if not ca and not cb: return 0.0\n",
    "    import difflib\n",
    "    return float(difflib.SequenceMatcher(None, ca, cb).ratio())\n",
    "\n",
    "\n",
    "def build_orbit_graph_from_stanza(stanza):\n",
    "    units=[]\n",
    "    for li, line in enumerate(stanza.get(\"lines\",[])):\n",
    "        for ord_idx, u in enumerate(line.get(\"orbit_units\",[])):\n",
    "            uid = u.get(\"id\", f\"l{li}_u{ord_idx}_{u.get('text')}\")\n",
    "            units.append({\"id\": uid, \"text\": u.get(\"text\"), \"line\": li, \"ord\": ord_idx, \"raw\":u})\n",
    "    id_map = {u[\"id\"]:u for u in units}\n",
    "    def match_by_text(target):\n",
    "        res=[]\n",
    "        for u in units:\n",
    "            if target.lower() in (u[\"text\"] or \"\").lower():\n",
    "                res.append(u[\"id\"])\n",
    "        return res\n",
    "    edges={}\n",
    "    def add_edge(a,b,w):\n",
    "        if a==b: return\n",
    "        key = tuple(sorted((a,b)))\n",
    "        edges[key] = max(edges.get(key,0.0), float(w))\n",
    "    # adjacency and same-line non-neighbors\n",
    "    for u in units:\n",
    "        for v in units:\n",
    "            if u[\"line\"]==v[\"line\"]:\n",
    "                d = abs(u[\"ord\"]-v[\"ord\"])\n",
    "                if d==1:\n",
    "                    add_edge(u[\"id\"], v[\"id\"], 1.0)\n",
    "                elif d>1:\n",
    "                    add_edge(u[\"id\"], v[\"id\"], 0.5)\n",
    "    # combine_with\n",
    "    for u in units:\n",
    "        comb = u[\"raw\"].get(\"combine_with\",[]) or []\n",
    "        for target in comb:\n",
    "            if target in id_map:\n",
    "                v = id_map[target]\n",
    "                if v[\"line\"]==u[\"line\"] and abs(v[\"ord\"]-u[\"ord\"])==1:\n",
    "                    add_edge(u[\"id\"], v[\"id\"], 1.5)\n",
    "                else:\n",
    "                    add_edge(u[\"id\"], v[\"id\"], 2.0)\n",
    "            else:\n",
    "                matches = match_by_text(target)\n",
    "                if matches:\n",
    "                    for mid in matches:\n",
    "                        v = id_map[mid]\n",
    "                        if v[\"line\"]==u[\"line\"] and abs(v[\"ord\"]-u[\"ord\"])==1:\n",
    "                            add_edge(u[\"id\"], mid, 1.5)\n",
    "                        else:\n",
    "                            add_edge(u[\"id\"], mid, 2.0)\n",
    "                else:\n",
    "                    tid = f\"ext::{target}_{random.randint(1,9999)}\"\n",
    "                    if tid not in id_map:\n",
    "                        id_map[tid] = {\"id\":tid,\"text\":target,\"line\":None,\"ord\":None}\n",
    "                        units.append(id_map[tid])\n",
    "                    add_edge(u[\"id\"], tid, 2.0)\n",
    "    node_list = [{\"id\":u[\"id\"], \"text\":u[\"text\"], \"line\":u.get(\"line\",None)} for u in units]\n",
    "    edge_list = [(a,b,w) for (a,b),w in edges.items()]\n",
    "    return node_list, edge_list\n",
    "\n",
    "# snapshot renderer -> returns PIL Image\n",
    "def snapshot_graph_image(nodes, edges, energy=0.0, title=None, label_nodes=False):\n",
    "    G = nx.Graph()\n",
    "    for n in nodes:\n",
    "        nid = n[\"id\"] if isinstance(n, dict) else str(n)\n",
    "        lab = n.get(\"text\", nid) if isinstance(n, dict) else str(n)\n",
    "        G.add_node(nid, label=lab, line=(n.get(\"line\") if isinstance(n, dict) else None))\n",
    "    for u,v,w in edges:\n",
    "        uid = u if isinstance(u,str) else (u.get(\"id\") if isinstance(u, dict) else str(u))\n",
    "        vid = v if isinstance(v,str) else (v.get(\"id\") if isinstance(v, dict) else str(v))\n",
    "        if uid!=vid:\n",
    "            G.add_edge(uid, vid, weight=float(w))\n",
    "    if len(G.nodes)==0:\n",
    "        return make_blank_frame()\n",
    "    n_nodes = max(1, len(G.nodes))\n",
    "    k = 0.8 / math.sqrt(n_nodes)\n",
    "    pos = nx.spring_layout(G, seed=42, weight=\"weight\", k=k, iterations=160)\n",
    "    rng = np.random.RandomState(42)\n",
    "    for key in list(pos.keys()):\n",
    "        pos[key] = pos[key] + rng.uniform(-0.02,0.02,size=2)\n",
    "    # create matplotlib canvas and draw\n",
    "    fig, ax = plt.subplots(figsize=(W/100, H/100), dpi=100)\n",
    "    ax.set_facecolor((0.03,0.03,0.05))\n",
    "    ax.set_xticks([]); ax.set_yticks([])\n",
    "    ax.set_xlim(-1.1,1.1); ax.set_ylim(-1.1,1.1)\n",
    "    weights = [d.get(\"weight\",1.0) for _,_,d in G.edges(data=True)]\n",
    "    maxw = max(weights) if weights else 1.0\n",
    "    for u,v,d in G.edges(data=True):\n",
    "        x1,y1 = pos[u]; x2,y2 = pos[v]\n",
    "        lw = 0.6 + 2.2*(d.get(\"weight\",1.0)/maxw)\n",
    "        alpha = 0.25 + 0.75*float(energy)\n",
    "        ax.plot([x1,x2],[y1,y2], lw=lw, color=(0.6,0.8,1.0,alpha))\n",
    "    deg = dict(G.degree(weight=\"weight\"))\n",
    "    maxdeg = max(deg.values()) if deg else 1.0\n",
    "    for n in G.nodes():\n",
    "        x,y = pos[n]\n",
    "        dval = deg.get(n, 0.0)\n",
    "        norm = (dval/maxdeg) if maxdeg>0 else 0.0\n",
    "        r = 0.02 + 0.06*(1+norm)\n",
    "        brightness = 0.2 + 0.8*float(energy)\n",
    "        circ = plt.Circle((x,y), r, color=(brightness*0.2, brightness*0.5, brightness*1.0), ec=(0.1,0.12,0.15), lw=1.0)\n",
    "        ax.add_patch(circ)\n",
    "    if title:\n",
    "        ax.text(-0.98, 0.95, title, color=(0.8,0.9,1.0), fontsize=10)\n",
    "    # grab as PIL image\n",
    "    fig.canvas.draw()\n",
    "    # img = Image.frombytes('RGB', fig.canvas.get_width_height(), fig.canvas.tostring_rgb())\n",
    "    # --- FIX for matplotlib >=3.9 ---\n",
    "    canvas = fig.canvas\n",
    "    w, h = canvas.get_width_height()\n",
    "    try:\n",
    "        buf = canvas.tostring_rgb()  # older versions\n",
    "    except AttributeError:\n",
    "        buf = canvas.buffer_rgba()   # newer versions\n",
    "    img = Image.frombuffer('RGBA' if len(buf) == w*h*4 else 'RGB', (w, h), buf, 'raw')\n",
    "\n",
    "    if img.mode != \"RGB\":\n",
    "        img = img.convert(\"RGB\")\n",
    "\n",
    "    plt.close(fig)\n",
    "    if label_nodes:\n",
    "        # The labeled image will be returned; labels will be drawn later via blending to create fade-in\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        # font = get_font(12)\n",
    "        font = get_font(28)\n",
    "        for n in G.nodes():\n",
    "            x,y = pos[n]\n",
    "            px = int(((x+1)/2.0)*W)\n",
    "            py = int(((1-y)/2.0)*H)\n",
    "            lab = G.nodes[n].get(\"label\",\"\")\n",
    "            draw.text((px,py), str(lab), fill=(255,255,255), font=font, anchor=\"mm\")\n",
    "        return img\n",
    "    else:\n",
    "        return img\n",
    "\n",
    "# function: blend unlabeled->labeled frames to create label fade-in frames\n",
    "def labeled_fade_frames(unlabeled_img, labeled_img, steps=ORBIT_LABEL_FADE_STEPS):\n",
    "    frames=[]\n",
    "    for i in range(steps):\n",
    "        alpha = (i+1)/steps\n",
    "        blended = Image.blend(unlabeled_img, labeled_img, alpha=alpha)\n",
    "        frames.append(blended)\n",
    "    return frames\n",
    "\n",
    "# pulse stanza renderer: returns list of PIL images in order (to be converted to ImageClips)\n",
    "def render_pulse_stanza_images(stanza_idx, stanza):\n",
    "    out_images=[]\n",
    "    lines = stanza.get(\"lines\", [])\n",
    "    # collect couplets (es,en)\n",
    "    couplets=[]\n",
    "    i=0\n",
    "    while i < len(lines)-1:\n",
    "        a=lines[i]; b=lines[i+1]\n",
    "        if a.get(\"lang\",\"\").lower().startswith(\"es\") and b.get(\"lang\",\"\").lower().startswith(\"en\"):\n",
    "            couplets.append((a,b)); i+=2\n",
    "        else:\n",
    "            i+=1\n",
    "    # compute phon/sem per couplet\n",
    "    phon_vals=[]; sem_vals=[]; glyph_counts=[]\n",
    "    for es,en in couplets:\n",
    "        p = phonetic_similarity(es.get(\"text\",\"\"), en.get(\"text\",\"\"))\n",
    "        s = semantic_similarity(es.get(\"text\",\"\"), en.get(\"text\",\"\"))\n",
    "        phon_vals.append(p); sem_vals.append(1.0 - s)\n",
    "        gcount = len(es.get(\"glyphs\",[])) + len(en.get(\"glyphs\",[]))\n",
    "        glyph_counts.append(gcount)\n",
    "    # dynamic evolving trajectory: produce incremental plot images (one per couplet)\n",
    "    trajectory_imgs=[]\n",
    "    if len(couplets)>0:\n",
    "        for idx in range(len(couplets)):\n",
    "            x = list(range(idx+1))\n",
    "            phon = phon_vals[:idx+1]\n",
    "            sem = sem_vals[:idx+1]\n",
    "            comb = [ph - sc for ph,sc in zip(phon, sem)]\n",
    "            fig, ax = plt.subplots(figsize=(W/100,H/100))\n",
    "            ax.set_facecolor((0.02,0.02,0.04))\n",
    "            times = [i+1 for i in x]\n",
    "            ax.plot(times, phon, label=\"phonetic_sim\", color=(0.2,0.8,1.0), lw=3)\n",
    "            ax.plot(times, sem, label=\"semantic_contrast\", color=(1.0,0.5,0.2), lw=3)\n",
    "            ax.plot(times, comb, label=\"phon-sem\", color=(0.95,0.95,0.6), lw=2, linestyle='--')\n",
    "            ax.set_xlim(0.5, max(3, times[-1]+0.5))\n",
    "            ax.set_ylim(-1.0, 1.0)\n",
    "            ax.legend(loc='upper right', fontsize=10)\n",
    "            ax.set_title(f\"Stanza {stanza.get('id','?')} trajectory (couplet {idx+1})\", color='white')\n",
    "            fig.canvas.draw()\n",
    "            # traj_img = Image.frombytes('RGB', fig.canvas.get_width_height(), fig.canvas.tostring_rgb())\n",
    "            # --- FIX for matplotlib >=3.9 (compatibility) ---\n",
    "            canvas = fig.canvas\n",
    "            w, h = canvas.get_width_height()\n",
    "            try:\n",
    "                buf = canvas.tostring_rgb()  # for matplotlib <3.9\n",
    "            except AttributeError:\n",
    "                buf = canvas.buffer_rgba()   # for matplotlib ≥3.9\n",
    "            traj_img = Image.frombuffer('RGBA' if len(buf) == w*h*4 else 'RGB', (w, h), buf, 'raw')\n",
    "\n",
    "            if traj_img.mode != \"RGB\":\n",
    "                traj_img = traj_img.convert(\"RGB\")\n",
    "\n",
    "            plt.close(fig)\n",
    "            # center on black background\n",
    "            bg = make_blank_frame()\n",
    "            fg = traj_img.resize((int(W*0.8), int(H*0.45)), Image.Resampling.LANCZOS)\n",
    "            pasted = paste_center(bg, fg, offset=(0,-50))\n",
    "            trajectory_imgs.append(pasted)\n",
    "    # now for each couplet, create sequence: ES flash (0.8s), EN flash (0.8s), glyph flash (0.6s), then trajectory snapshot (0.7s)\n",
    "    for idx, (es,en) in enumerate(couplets):\n",
    "        # ES frame\n",
    "        f_es = make_blank_frame()\n",
    "        draw = ImageDraw.Draw(f_es)\n",
    "        font = get_font(36)\n",
    "        # font = get_font(47)\n",
    "        draw.text((W//2, H//2 - 10), es.get(\"text\",\"\"), font=font, fill=(240,240,240), anchor=\"mm\")\n",
    "        # EN frame\n",
    "        f_en = make_blank_frame()\n",
    "        draw2 = ImageDraw.Draw(f_en)\n",
    "        draw2.text((W//2, H//2 - 10), en.get(\"text\",\"\"), font=font, fill=(160,210,255), anchor=\"mm\")\n",
    "        out_images.append( (f_es, COUPLET_FLASH_SECONDS) )\n",
    "        out_images.append( (f_en, COUPLET_FLASH_SECONDS) )\n",
    "        # glyph flashes: render glyphs from both lines if any\n",
    "        glyphs = (es.get(\"glyphs\",[]) or []) + (en.get(\"glyphs\",[]) or [])\n",
    "        for g in glyphs:\n",
    "            fg_img = make_blank_frame()\n",
    "            dd = ImageDraw.Draw(fg_img)\n",
    "            # attempt to place glyph near target_word: approximate x by char index\n",
    "            target = g.get(\"target_word\",\"\")\n",
    "            jitter = g.get(\"jitter\",[12,6])\n",
    "            # approximate x offset by finding target in either es/en text\n",
    "            posx = W//2\n",
    "            posy = H//2\n",
    "            for txt in (es.get(\"text\",\"\"), en.get(\"text\",\"\")):\n",
    "                if target and target in txt:\n",
    "                    idx_char = txt.index(target)\n",
    "                    pct = idx_char / max(1, len(txt))\n",
    "                    posx = int(W*0.1 + pct*W*0.8) + random.randint(-jitter[0], jitter[0])\n",
    "                    posy = H//2 + random.randint(-jitter[1], jitter[1])\n",
    "                    break\n",
    "            fontg = get_font(33)\n",
    "            dd.text((posx,posy), g.get(\"char\", \"\"), font=fontg, fill=(220,240,200))\n",
    "            out_images.append( (fg_img, GLYPH_FLASH_SECONDS) )\n",
    "        # trajectory snapshot for this couplet (if exists)\n",
    "        if trajectory_imgs:\n",
    "            traj = trajectory_imgs[idx]\n",
    "            out_images.append( (traj, max(0.6, COUPLET_FLASH_SECONDS*0.75)) )\n",
    "\n",
    "    # final pulse stanza consolidated image (short)\n",
    "    if trajectory_imgs:\n",
    "        final_traj = trajectory_imgs[-1]\n",
    "    else:\n",
    "        final_traj = make_blank_frame()\n",
    "    out_images.append( (final_traj, FINAL_LABEL_SECONDS) )\n",
    "    # convert to list of (PIL img, duration)\n",
    "    return out_images\n",
    "\n",
    "# helper to convert (PIL,dur) list to moviepy ImageClip list (using numpy arrays)\n",
    "def images_to_clips(images_with_durations):\n",
    "    clips=[]\n",
    "    for img,dur in images_with_durations:\n",
    "        arr = pil_to_np(img)\n",
    "        clip = ImageClip(arr).with_duration(float(dur))\n",
    "        clips.append(clip)\n",
    "    return clips\n",
    "\n",
    "def build_video_from_structure(json_path, out_video):\n",
    "    data = load_json(json_path)\n",
    "    stanzas = data.get(\"stanzas\", [])\n",
    "    all_clips=[]\n",
    "    final_orbit_labeled_paths=[]\n",
    "    final_pulse_paths=[]\n",
    "    for si, stanza in enumerate(stanzas):\n",
    "        mode = stanza.get(\"mode\",\"orbiting_recursions\")\n",
    "        dur = stanza.get(\"duration\",10.0)\n",
    "        print(f\"Rendering stanza {si+1} mode={mode} duration={dur}s ...\")\n",
    "        out_dir = TMP_DIR / f\"stanza_{si+1}\"; out_dir.mkdir(parents=True, exist_ok=True)\n",
    "        if mode.startswith(\"orbit\"):\n",
    "            nodes, edges = build_orbit_graph_from_stanza(stanza)\n",
    "            n_lines = max(1, len(stanza.get(\"lines\",[])))\n",
    "            per_snap = max( (dur - FINAL_LABEL_SECONDS)/n_lines if dur>FINAL_LABEL_SECONDS else dur/(n_lines+1e-6), 0.5)\n",
    "            # generate snapshots progressively\n",
    "            active_nodes=[]\n",
    "            active_edges=[]\n",
    "            stanza_frames = []\n",
    "            energies = [0.4 + 0.1*math.sin(i) for i in range(n_lines+1)]\n",
    "            for li in range(n_lines):\n",
    "                new_nodes = [n for n in nodes if n.get(\"line\")==li]\n",
    "                active_nodes.extend(new_nodes)\n",
    "                active_ids = {n[\"id\"] for n in active_nodes}\n",
    "                active_edges = [(u,v,w) for (u,v,w) in edges if (u in active_ids and v in active_ids)]\n",
    "                img_unlabeled = snapshot_graph_image(active_nodes, active_edges, energy=energies[min(li,len(energies)-1)], title=f\"Stanza {si+1} • line {li+1}/{n_lines}\", label_nodes=False)\n",
    "                p = out_dir / f\"stanza{si+1}_line{li+1}.png\"; save_pil_img(img_unlabeled, p)\n",
    "                # add single frame (duration per_snap)\n",
    "                stanza_frames.append( (img_unlabeled, per_snap) )\n",
    "            # final labeled image\n",
    "            img_all_unlabeled = snapshot_graph_image(nodes, edges, energy=1.0, title=f\"Stanza {si+1} — final\", label_nodes=False)\n",
    "            img_all_labeled = snapshot_graph_image(nodes, edges, energy=1.0, title=f\"Stanza {si+1} — final\", label_nodes=True)\n",
    "            # produce fade-in frames blending unlabeled->labeled\n",
    "            fade_frames = labeled_fade_frames(img_all_unlabeled, img_all_labeled, steps=ORBIT_LABEL_FADE_STEPS)\n",
    "            # save final labeled for recap\n",
    "            final_path = out_dir / f\"stanza{si+1}_final_labeled.png\"\n",
    "            save_pil_img(img_all_labeled, final_path)\n",
    "            final_orbit_labeled_paths.append(final_path)\n",
    "            # append fade frames with short durations to stanza_frames\n",
    "            for fimg in fade_frames:\n",
    "                stanza_frames.append( (fimg, FINAL_LABEL_SECONDS / len(fade_frames)) )\n",
    "            # convert to clips and append\n",
    "            clips = images_to_clips(stanza_frames)\n",
    "            all_clips.extend(clips)\n",
    "        elif mode.startswith(\"pulse\"):\n",
    "            imgs_with_durs = render_pulse_stanza_images(si, stanza)\n",
    "            # save final traj image path for recap\n",
    "            if imgs_with_durs:\n",
    "                last_img, _ = imgs_with_durs[-1]\n",
    "                final_p = TMP_DIR / f\"stanza{si+1}_pulse_final.png\"\n",
    "                save_pil_img(last_img, final_p)\n",
    "                final_pulse_paths.append(final_p)\n",
    "            # convert to clips\n",
    "            clips = images_to_clips(imgs_with_durs)\n",
    "            all_clips.extend(clips)\n",
    "        else:\n",
    "            # fallback black for duration\n",
    "            all_clips.append(ImageClip(pil_to_np(make_blank_frame())).with_duration(dur))\n",
    "\n",
    "    # recap\n",
    "    recap_tiles = []\n",
    "    for p in final_orbit_labeled_paths + final_pulse_paths:\n",
    "        if p.exists():\n",
    "            # create small padded tile\n",
    "            im = Image.open(p).convert(\"RGB\").resize((W//2 - 20, H//2 - 20), Image.Resampling.LANCZOS)\n",
    "            bg = make_blank_frame()\n",
    "            tile = paste_center(bg, im)\n",
    "            recap_tiles.append(tile)\n",
    "    if recap_tiles:\n",
    "        # flash each quickly, then one 4s grid\n",
    "        quick = []\n",
    "        for t in recap_tiles:\n",
    "            quick.append( (t, 0.25) )\n",
    "        all_clips.extend(images_to_clips(quick))\n",
    "        # make 2x2 grid\n",
    "        # tiles = recap_tiles[:4]\n",
    "        # tiles = recap_tiles\n",
    "        grid = make_blank_frame()\n",
    "        for idx, im in enumerate(recap_tiles):\n",
    "            w2,h2 = im.size\n",
    "            # x = (idx % 2) * (W//2)\n",
    "            x = idx * (W//2)\n",
    "            # y = (idx // 2) * (H//2)\n",
    "            y = idx * (H//2)\n",
    "            grid.paste(im, (x, y))\n",
    "        # all_clips.append(ImageClip(pil_to_np(grid)).with_duration(4.0))\n",
    "        all_clips.append(ImageClip(pil_to_np(grid)).with_duration(1.3))\n",
    "\n",
    "    # concatenate all clips\n",
    "    final_video = concatenate_videoclips(all_clips, method=\"compose\")\n",
    "    # attach audio master if exists\n",
    "    if Path(AUDIO_MASTER).exists():\n",
    "        aud = AudioFileClip(AUDIO_MASTER)\n",
    "        try:\n",
    "            aud = aud.subclipped(0, final_video.duration)\n",
    "        except Exception:\n",
    "            try:\n",
    "                aud = aud.subclip(0, final_video.duration)\n",
    "            except Exception:\n",
    "                pass\n",
    "        try:\n",
    "            final_video = final_video.with_audio(aud)\n",
    "        except Exception:\n",
    "            try:\n",
    "                final_video = final_video.set_audio(aud)\n",
    "            except Exception:\n",
    "                pass\n",
    "    # write out\n",
    "    final_video.write_videofile(out_video, fps=FPS, codec=\"libx264\", audio_codec=\"aac\")\n",
    "    print(\"Saved:\", out_video)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7789fc80-b3a1-4ce2-be95-911b8ebecad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendering stanza 1 mode=orbiting_recursions duration=15s ...\n",
      "Rendering stanza 2 mode=pulse_flash_spectral duration=25s ...\n",
      "Rendering stanza 3 mode=orbiting_recursions duration=25s ...\n",
      "Rendering stanza 4 mode=pulse_flash_spectral duration=35s ...\n",
      "Rendering stanza 5 mode=orbiting_recursions duration=20s ...\n",
      "Rendering stanza 6 mode=pulse_flash_spectral duration=63s ...\n",
      "Rendering stanza 7 mode=orbiting_recursions duration=25s ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Building video MARGENTO_World_Poem_1_Quantum_AHiRA_4.mp4.\n",
      "MoviePy - Writing audio in MARGENTO_World_Poem_1_Quantum_AHiRA_4TEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing video MARGENTO_World_Poem_1_Quantum_AHiRA_4.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done !\n",
      "MoviePy - video ready MARGENTO_World_Poem_1_Quantum_AHiRA_4.mp4\n",
      "Saved: MARGENTO_World_Poem_1_Quantum_AHiRA_4.mp4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if not Path(JSON_PATH).exists():\n",
    "        print(\"Missing JSON, please add poem_structure.json in working dir.\")\n",
    "        sys.exit(1)\n",
    "    OUT_VIDEO = \"MARGENTO_World_Poem_1_Quantum_AHiRA_4.mp4\"\n",
    "    build_video_from_structure(JSON_PATH, OUT_VIDEO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d1291a-9200-49ec-83c3-c9644fa05e90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c2dfb9-4994-466b-8a4e-08ff58a03475",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (venv310)",
   "language": "python",
   "name": "venv310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
